import numpy as np
import torch
import random
from scipy.ndimage.interpolation import zoom
from torch.utils.data import Dataset
from torchvision import transforms as T
from torchvision.transforms import functional as tF
from typing import Callable
import os
import cv2
from scipy import ndimage

def random_rot_flip(image, label):
    k = np.random.randint(0, 4)
    image = np.rot90(image, k)
    label = np.rot90(label, k)
    axis = np.random.randint(0, 2)
    image = np.flip(image, axis=axis).copy()
    label = np.flip(label, axis=axis).copy()
    return image, label

def random_rotate(image, label):
    angle = np.random.randint(-20, 20)
    image = ndimage.rotate(image, angle, order=0, reshape=False)
    label = ndimage.rotate(label, angle, order=0, reshape=False)
    return image, label

class RandomGenerator_Monu(object):
    def __init__(self, output_size):
        self.output_size = output_size

    def __call__(self, sample):
        image, label = sample['image'], sample['label']
        image, label = tF.to_pil_image(image), tF.to_pil_image(label)
        x, y = image.size
        if random.random() > 0.5:
            image, label = random_rot_flip(image, label)
        elif random.random() > 0.5:
            image, label = random_rotate(image, label)

        if x != self.output_size[0] or y != self.output_size[1]:
            image = zoom(image, (self.output_size[0] / x, self.output_size[1] / y), order=3)  # why not 3?
            label = zoom(label, (self.output_size[0] / x, self.output_size[1] / y), order=0)
        image = tF.to_tensor(image)
        label = to_long_tensor(label)
        sample = {'image': image, 'label': label}
        return sample

class ValGenerator(object):
    def __init__(self, output_size):
        self.output_size = output_size

    def __call__(self, sample):
        image, label = sample['image'], sample['label']
        image, label = tF.to_pil_image(image), tF.to_pil_image(label)
        x, y = image.size
        if x != self.output_size[0] or y != self.output_size[1]:
            image = zoom(image, (self.output_size[0] / x, self.output_size[1] / y), order=3)  # why not 3?
            label = zoom(label, (self.output_size[0] / x, self.output_size[1] / y), order=0)
        image = tF.to_tensor(image)
        label = to_long_tensor(label)
        sample = {'image': image, 'label': label}
        return sample

def to_long_tensor(pic):
    # handle numpy array
    img = torch.from_numpy(np.array(pic, np.uint8))
    # backward compatibility
    return img.long()

def correct_dims(*images):
    corr_images = []
    # print(images)
    for img in images:
        if len(img.shape) == 2:
            corr_images.append(np.expand_dims(img, axis=2))
        else:
            corr_images.append(img)

    if len(corr_images) == 1:
        return corr_images[0]
    else:
        return corr_images

class ImageToImage2D(Dataset):
    """
    Reads the images and applies the augmentation transform on them.
    Usage:
        1. If used without the unet.model.Model wrapper, an instance of this object should be passed to
           torch.utils.data.DataLoader. Iterating through this returns the tuple of image, mask and image
           filename.
        2. With unet.model.Model wrapper, an instance of this object should be passed as train or validation
           datasets.

    Args:
        dataset_path: path to the dataset. Structure of the dataset should be:
            dataset_path
              |-- images
                  |-- img001.png
                  |-- img002.png
                  |-- ...
              |-- masks
                  |-- img001.png
                  |-- img002.png
                  |-- ...

        joint_transform: augmentation transform, an instance of JointTransform2D. If bool(joint_transform)
            evaluates to False, torchvision.transforms.ToTensor will be used on both image and mask.
        one_hot_mask: bool, if True, returns the mask in one-hot encoded form.
    """

    def __init__(self, dataset_path: str, joint_transform: Callable = None, one_hot_mask: int = False, image_size: int =224) -> None:
        self.dataset_path = dataset_path
        self.image_size = image_size
        self.input_path = os.path.join(dataset_path, 'img')
        self.output_path = os.path.join(dataset_path, 'labelcol')
        self.images_list = os.listdir(self.input_path)
        self.one_hot_mask = one_hot_mask

        if joint_transform:
            self.joint_transform = joint_transform
        else:
            to_tensor = T.ToTensor()
            self.joint_transform = lambda x, y: (to_tensor(x), to_tensor(y))

    def __len__(self):
        return len(os.listdir(self.input_path))

    def __getitem__(self, idx):

        image_filename = self.images_list[idx]

        image = cv2.imread(os.path.join(self.input_path, image_filename))

        image = cv2.resize(image,(self.image_size,self.image_size))

        mask = cv2.imread(os.path.join(self.output_path, image_filename[: -3] + "png"),0)

        mask = cv2.resize(mask,(self.image_size,self.image_size))
        mask[mask<=0] = 0
        mask[mask>0] = 1

        image, mask = correct_dims(image, mask)
        sample = {'image': image, 'label': mask}

        if self.joint_transform:
            sample = self.joint_transform(sample)

        if self.one_hot_mask:
            assert self.one_hot_mask > 0, 'one_hot_mask must be nonnegative'
            mask = torch.zeros((self.one_hot_mask, mask.shape[1], mask.shape[2])).scatter_(0, mask.long(), 1)

        return sample, image_filename

import torch.optim
import os
import time
from utils import *
import warnings
warnings.filterwarnings("ignore")
from sklearn.metrics import jaccard_score
def print_summary(epoch, i, nb_batch, loss, loss_name, batch_time,
                  average_loss, average_time, iou, average_iou,
                  dice, average_dice, acc, average_acc, mode, lr, logger):
    '''
        mode = Train or Test
    '''
    summary = '   [' + str(mode) + '] Epoch: [{0}][{1}/{2}]  '.format(
        epoch, i, nb_batch)
    string = ''
    string += 'Loss:{:.3f} '.format(loss)
    string += '(Avg {:.4f}) '.format(average_loss)
    string += 'Dice:{:.4f} '.format(dice)
    string += '(Avg {:.4f}) '.format(average_dice)
    if mode == 'Train':
        string += 'LR {:.2e}   '.format(lr)
    string += '(AvgTime {:.1f})   '.format(average_time)
    summary += string
    logger.info(summary)


##################################################################################
#=================================================================================
#          Train One Epoch
#=================================================================================
##################################################################################
def train_one_epoch_MoNu(loader, model, criterion, optimizer, epoch, lr_scheduler, logger,args):
    logging_mode = 'Train' if model.training else 'Val'

    end = time.time()
    time_sum, loss_sum = 0, 0
    dice_sum, iou_sum, acc_sum = 0.0, 0.0, 0.0

    dices = []
    for i, (sampled_batch, names) in enumerate(loader, 1):

        try:
            loss_name = criterion._get_name()
        except AttributeError:
            loss_name = criterion.__name__

        # Take variable and put them to GPU
        images, masks = sampled_batch['image'], sampled_batch['label']
        images, masks = images.cuda(), masks.cuda()


        # ====================================================
        #             Compute loss
        # ====================================================

        preds = model(images)
        out_loss = criterion(preds, masks.float())  # Loss


        if model.training:
            optimizer.zero_grad()
            out_loss.backward()
            optimizer.step()

        train_iou = iou_on_batch(masks,preds)
        train_dice = criterion._show_dice(preds, masks.float())

        batch_time = time.time() - end
        dices.append(train_dice)

        time_sum += len(images) * batch_time
        loss_sum += len(images) * out_loss
        iou_sum += len(images) * train_iou
        dice_sum += len(images) * train_dice

        if i == len(loader):
            average_loss = loss_sum / (args.batch_size*(i-1) + len(images))
            average_time = time_sum / (args.batch_size*(i-1) + len(images))
            train_iou_average = iou_sum / (args.batch_size*(i-1) + len(images))
            # train_acc_average = acc_sum / (args.batch_size*(i-1) + len(images))
            train_dice_avg = dice_sum / (args.batch_size*(i-1) + len(images))
        else:
            average_loss = loss_sum / (i * args.batch_size)
            average_time = time_sum / (i * args.batch_size)
            train_iou_average = iou_sum / (i * args.batch_size)
            # train_acc_average = acc_sum / (i * args.batch_size)
            train_dice_avg = dice_sum / (i * args.batch_size)

        end = time.time()
        torch.cuda.empty_cache()

        if i % 1 == 0:
            print_summary(epoch + 1, i, len(loader), out_loss, loss_name, batch_time,
                          average_loss, average_time, train_iou, train_iou_average,
                          train_dice, train_dice_avg, 0, 0,  logging_mode,
                          lr=min(g["lr"] for g in optimizer.param_groups),logger=logger)


        torch.cuda.empty_cache()

    if lr_scheduler is not None:
        lr_scheduler.step()

    return average_loss, train_dice_avg, train_iou_average

def iou_on_batch(masks, pred):
    '''Computes the mean Area Under ROC Curve over a batch during training'''
    ious = []

    for i in range(pred.shape[0]):
        pred_tmp = pred[i][0].cpu().detach().numpy()
        # print("www",np.max(prediction), np.min(prediction))
        mask_tmp = masks[i].cpu().detach().numpy()
        pred_tmp[pred_tmp>=0.5] = 1
        pred_tmp[pred_tmp<0.5] = 0
        # print("2",np.sum(tmp))
        mask_tmp[mask_tmp>0] = 1
        mask_tmp[mask_tmp<=0] = 0
        # print("rrr",np.max(mask), np.min(mask))
        ious.append(jaccard_score(mask_tmp.reshape(-1), pred_tmp.reshape(-1)))
    return np.mean(ious)

def val_one_epoch_MoNu(loader, model, criterion, logger, args):
    """
    专门用于验证的函数，确保不更新模型参数
    """
    model.eval()  # 确保模型处于评估模式
    
    end = time.time()
    time_sum, loss_sum = 0, 0
    dice_sum, iou_sum = 0.0, 0.0

    dices = []
    
    with torch.no_grad():  # 确保不计算梯度
        for i, (sampled_batch, names) in enumerate(loader, 1):
            try:
                loss_name = criterion._get_name()
            except AttributeError:
                loss_name = criterion.__name__

            # Take variable and put them to GPU
            images, masks = sampled_batch['image'], sampled_batch['label']
            images, masks = images.cuda(), masks.cuda()

            # Forward pass only, no backpropagation
            preds = model(images)
            out_loss = criterion(preds, masks.float())

            # Compute metrics
            val_iou = iou_on_batch(masks, preds)
            val_dice = criterion._show_dice(preds, masks.float())

            batch_time = time.time() - end
            dices.append(val_dice)

            time_sum += len(images) * batch_time
            loss_sum += len(images) * out_loss.item()  # 使用.item()获取标量值
            iou_sum += len(images) * val_iou
            dice_sum += len(images) * val_dice

            if i == len(loader):
                average_loss = loss_sum / (args.batch_size*(i-1) + len(images))
                average_time = time_sum / (args.batch_size*(i-1) + len(images))
                val_iou_average = iou_sum / (args.batch_size*(i-1) + len(images))
                val_dice_avg = dice_sum / (args.batch_size*(i-1) + len(images))
            else:
                average_loss = loss_sum / (i * args.batch_size)
                average_time = time_sum / (i * args.batch_size)
                val_iou_average = iou_sum / (i * args.batch_size)
                val_dice_avg = dice_sum / (i * args.batch_size)

            end = time.time()
            torch.cuda.empty_cache()

            if i % 1 == 0:
                print_summary(0, i, len(loader), out_loss.item(), loss_name, batch_time,
                              average_loss, average_time, val_iou, val_iou_average,
                              val_dice, val_dice_avg, 0, 0, 'Val', lr=0, logger=logger)

            torch.cuda.empty_cache()

    return average_loss, val_dice_avg, val_iou_average